# -*- coding: utf-8 -*-
"""testing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12sSFc-sb-LbXjK-pQE9Rpv35Yqd4qFFF
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone Darknet repository (if not already done)
!git clone https://github.com/AlexeyAB/darknet.git
# %cd darknet

# Modify Makefile to enable GPU and OpenCV
!sed -i 's/OPENCV=0/OPENCV=1/' Makefile
!sed -i 's/GPU=0/GPU=1/' Makefile
!sed -i 's/CUDNN=0/CUDNN=1/' Makefile
!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile

# Compile Darknet
!make

import cv2
from google.colab.patches import cv2_imshow
from google.colab import files

custom_data ="/content/darknet/custom.data"

print("Please upload your custom.data file:")
uploaded = files.upload()
custom_data = next(iter(uploaded))

print("Please upload your yolov4-aug22.cfg file:")
uploaded = files.upload()
cfg_file = next(iter(uploaded))

print("Please upload your yolov4-aug22.weights file:")
uploaded = files.upload()
weights_file = next(iter(uploaded))

print("Please upload your input video (output_video1.avi):")
uploaded = files.upload()
input_video = next(iter(uploaded))

# Run YOLOv4 on the video with custom data
!./darknet detector demo {custom_data} {cfg_file} {weights_file} {input_video} -thresh 0.25 -dont_show -ext_output -out_filename result_video.avi

# Run YOLOv4 and redirect output to a file
!./darknet detector demo {custom_data} {cfg_file} {weights_file} {input_video} -thresh 0.25 -dont_show -ext_output -out_filename result_video.avi > yolo_output.txt

import re

# Read the YOLOv4 output from the file
with open('yolo_output.txt', 'r') as file:
    yolo_output = file.read()

# Regex pattern to match the detection lines
pattern = r"(\w+): (\d+)%"

# Initialize variables
frame_detections = []
current_frame_detections = []
current_frame_confidences = []
total_confidence = 0
total_detections = 0

# Process each line of the output
for line in yolo_output.splitlines():
    matches = re.findall(pattern, line)

    if matches:
        for match in matches:
            class_name = match[0]
            confidence = int(match[1])
            current_frame_detections.append(class_name)
            current_frame_confidences.append(confidence)
            total_confidence += confidence
            total_detections += 1
    elif "FPS" in line:
        if current_frame_detections:
            frame_detections.append({
                'num_detections': len(current_frame_detections),
                'avg_confidence': sum(current_frame_confidences) / len(current_frame_confidences)
            })
            current_frame_detections = []
            current_frame_confidences = []

# Handle the last frame if the output does not end with "FPS"
if current_frame_detections:
    frame_detections.append({
        'num_detections': len(current_frame_detections),
        'avg_confidence': sum(current_frame_confidences) / len(current_frame_confidences)
    })

# Print per-frame results
for i, frame_data in enumerate(frame_detections):
    print(f"Frame {i+1}: {frame_data['num_detections']} detections, Avg confidence: {frame_data['avg_confidence']:.2f}%")

# Calculate overall confidence
if total_detections > 0:
    overall_avg_confidence = total_confidence / total_detections
    print(f"\nOverall: {total_detections} detections, Overall average confidence: {overall_avg_confidence:.2f}%")
else:
    print("\nNo detections were made.")

# Function to play the output video
import cv2
from google.colab.patches import cv2_imshow

def play_video(video_path):
    cap = cv2.VideoCapture(video_path)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Display the frame
        cv2_imshow(frame)

        # Clear the output to avoid cluttering
        from IPython.display import clear_output
        clear_output(wait=True)

        # Wait for a short time and check if the user wants to quit
        if cv2.waitKey(25) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# Play the output video
print("Playing the output video:")
play_video('result_video.avi')

